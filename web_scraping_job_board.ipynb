{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping indeed website for data science jobs based on Greg Reda's [excellent tutorial](http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/) and Jesse Steinweg's [excellent analysis](https://jessesw.com/Data-Science-Skills/) and finally, Sung Pil Moon's [awesome analysis](http://blog.nycdatascience.com/students-work/project-3-web-scraping-company-data-from-indeed-com-and-dice-com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Admin and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've already created a virtual environment in conda by downloading bs4. Please feel free to use my environment.yaml to create a similar virtual env. I'll update it as I go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) What do I want to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://au.indeed.com/jobs?as_and=&as_phr=&as_any=%22customer+analytics%22+%22data+analysis%22&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=50&l=&fromage=any&limit=10&sort=&psf=advsrch\n",
    "\n",
    "OR\n",
    "\n",
    "http://au.indeed.com/jobs?as_and=&as_phr=&as_any=%22customer+analytics%22+%22data+analysis%22&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=0&l=Sydney+NSW&fromage=last&limit=10&sort=&psf=advsrch\n",
    "\n",
    "in a nice tabular format for data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) String together webpage url based on different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create logic for converting different search parameters such as search query, city, salary etc. as separate lists and then stringing them together into one final query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_query = base_url + job_query_string + company_name + salary + location + fromage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start of the url - this will not change because I'm including search query to search\n",
    "# anywhere in the job ad. Not just the job title.\n",
    "base_url = 'http://au.indeed.com/jobs?as_and=&as_phr=&as_any='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job query string inputs as parameters are stored in job_query1, 2 and 3. Restrict to only 3 parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1 - collect 3 search queries<br/>\n",
    "When you refactor this, make sure this is converted into parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_query1 = 'data scientist'\n",
    "job_query2 = 'customer analytics'\n",
    "job_query3 = 'data analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2 - create query string in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%22data+scientist%22+%22customer+analytics%22+%22data+analysis%22'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) within search string, spaces are replaced by '+' in html\n",
    "# 2) each search query is preceded and succeeded by a \"%22\"\n",
    "# 3) string the elements of the list into one string separated by a \"+\"\n",
    "job_query_string = []\n",
    "job_query_string.append(\"%22\" + job_query1.replace(\" \",\"+\") + \"%22\")\n",
    "job_query_string.append(\"%22\" + job_query2.replace(\" \",\"+\") + \"%22\")\n",
    "job_query_string.append(\"%22\" + job_query3.replace(\" \",\"+\") + \"%22\")\n",
    "job_query_string = \"+\".join(job_query_string)\n",
    "job_query_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company name, salary, location, fromage - not working on these right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_name=''\n",
    "salary=''\n",
    "location=''\n",
    "fromage='any'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://au.indeed.com/jobs?as_and=&as_phr=&as_any=%22data+scientist%22+%22customer+analytics%22+%22data+analysis%22&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=50&l=&fromage=any&limit=10&sort=&psf=advsrch'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_query = [base_url,job_query_string,'&as_not=&as_ttl=&as_cmp=',company_name,\n",
    "               '&jt=all&st=&salary=',salary,'&radius=50&l=',location,\n",
    "               '&fromage=',fromage,'&limit=10&sort=&psf=advsrch']\n",
    "final_query = \"\".join(final_query)\n",
    "final_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Open website and read it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: Open the first page <br/>\n",
    "Step2: Get the html of the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = urlopen(final_query).read()  \n",
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3: find out how many jobs returned from the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jobs 1 to 10 of 963'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_jobs_page_area = soup.find(id=\"searchCount\").string.encode('utf-8')\n",
    "number_of_jobs_page_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '10', '963']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_jobs = re.findall('\\d+', number_of_jobs_page_area)\n",
    "number_of_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_jobs = int(number_of_jobs[2])\n",
    "total_number_of_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4: calculate how many pages to scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#round up the # of records divided by 10 as the number of pages in order to ensure coverage. \n",
    "number_of_pages_to_scroll = np.ceil(total_number_of_jobs/10.0)\n",
    "number_of_pages_to_scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Load all the deets into separate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all the deets of each row. One row pertains to one job\n",
    "# incidentally, i noticed that the class \"row result\" was only picking 9 results in the first page.\n",
    "# this was because the last row was populated in another class 'lastRow row result'\n",
    "\n",
    "targetElements = soup.findAll('div', attrs = {'class' : ' row result'})\n",
    "targetElements.extend(soup.findAll('div', attrs = {'class' : 'lastRow row result'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(targetElements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for elem in targetElements:\n",
    "    #print elem # commenting out this line so as to remove metadata from the notebook\n",
    "    print \"\\n\"\n",
    "    print \"*****************************************************\"\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Program and Service Advisor',\n",
       " 'Reliability Engineer - Christmas Creek',\n",
       " 'Data Analyst / Administrator',\n",
       " 'Test Data Analyst',\n",
       " 'Stock Coordinator - Support Centre QLD',\n",
       " 'Scholarly Teaching Fellow',\n",
       " 'Global Purchasing Procurement Analyst',\n",
       " 'Insight Analytics Manager',\n",
       " 'Production Reliabilty Engineer',\n",
       " 'RTO Administration Officer']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobtitle = []\n",
    "for elem in targetElements:\n",
    "    #print elem.find('a', attrs = {'class':'turnstileLink'}).attrs['title']\n",
    "    jobtitle.append(elem.find('a', attrs = {'class':'turnstileLink'}).attrs['title'])\n",
    "\n",
    "jobtitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Company Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Victorian Government',\n",
       " 'Fortescue Metals Group',\n",
       " 'Brookfield',\n",
       " 'UniSuper',\n",
       " 'Lorna Jane',\n",
       " 'Macquarie University',\n",
       " 'PepsiCo',\n",
       " 'PwC',\n",
       " 'GlaxoSmithKline',\n",
       " 'Downer EDI']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyname = []\n",
    "for elem in targetElements:\n",
    "    companyname.append(elem.find('span', attrs = {'itemprop':'name'}).getText().strip().encode('utf-8'))\n",
    "    \n",
    "companyname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geelong VIC',\n",
       " 'Pilbara WA',\n",
       " 'Sydney NSW',\n",
       " 'Melbourne VIC',\n",
       " 'Queensland',\n",
       " 'Macquarie University NSW',\n",
       " 'Chatswood NSW',\n",
       " 'Melbourne VIC',\n",
       " 'Melbourne VIC',\n",
       " 'Laverton WA']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = []\n",
    "for elem in targetElements:\n",
    "    location.append(elem.find('span', attrs = {'itemprop':'addressLocality'}).getText().strip().encode('utf-8'))\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In particular, a highly motivated individual with great data analysis and relationship management skills with health sector experience would suit this role....',\n",
       " 'Analysis and reporting of fleet performance. The role of the reliability engineer is to provide technical support using initiatives and applying reliability...',\n",
       " 'Undertake data analysis, cleansing, validation and updates. Management of data including; Data and system incident management;...',\n",
       " 'Extensive data extract, analysis and reporting experience. As a Test Data Analyst you will perform complex data analysis testing to ensure that changes to new...',\n",
       " 'Analysis of sales data and through reports to supply. Combining a love of LJ Active Wear and data analysis with....',\n",
       " 'Experience in acoustic, articulatory and/or perceptual speech data analysis. Macquarie is the university of pioneering minds....',\n",
       " 'You will be responsible for managing performance metrics, insightful reports, data analytics, and commodity risk compliance, coupled with regular engagement...',\n",
       " 'Insight Analytics Manager. PwC is a world leader in the use of data analytics to help business and government clients make better decisions and improve their...',\n",
       " 'High understanding of business management, leadership, problem solving techniques, data analysis is required. Analyses failure rate data....',\n",
       " 'Strong computer and data analysis skills that extend to report collation and presentation. High degree of efficiency and effectiveness with managing large...']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = []\n",
    "for elem in targetElements:\n",
    "    summary.append(elem.find('span', attrs = {'class':'summary'}).getText().strip().encode('utf-8'))\n",
    "    \n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cant seem to get this to work for some reason\n",
    "company_rating = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('span', attrs = [{'class':'ratingNumber'}]) is None:\n",
    "        company_rating.append(None)\n",
    "    else:\n",
    "        company_rating.append(elem.find('span', attrs = {'class':'ratingNumber'})\n",
    "                                     .getText().strip().encode('utf-8'))\n",
    "    \n",
    "company_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company rating - Number of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " '23 reviews',\n",
       " '21 reviews',\n",
       " None,\n",
       " '19 reviews',\n",
       " '11 reviews',\n",
       " '4,712 reviews',\n",
       " '2,342 reviews',\n",
       " '1,581 reviews',\n",
       " '47 reviews']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_rating_counts = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('span', attrs = {'class':'slNoUnderline'}) is None:\n",
    "        company_rating_counts.append(None)\n",
    "    else:\n",
    "        company_rating_counts.append(elem.find('span', attrs = {'class':'slNoUnderline'})\n",
    "                                     .getText().strip().encode('utf-8'))\n",
    "\n",
    "company_rating_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advertised number of days ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12 days ago',\n",
       " '3 days ago',\n",
       " '28 days ago',\n",
       " '11 days ago',\n",
       " '3 days ago',\n",
       " '13 days ago',\n",
       " '6 days ago',\n",
       " '30+ days ago',\n",
       " '4 days ago',\n",
       " '11 days ago']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advertised_number_of_days_ago = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('span', attrs = {'class':'date'}) is None:\n",
    "        advertised_number_of_days_ago.append(None)\n",
    "    else:\n",
    "        advertised_number_of_days_ago.append(elem.find('span', attrs = {'class':'date'})\n",
    "                                     .getText().strip().encode('utf-8'))\n",
    "\n",
    "advertised_number_of_days_ago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " '$68,324 - $92,000 a year',\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('nobr') is None:\n",
    "        salary.append(None)\n",
    "    else:\n",
    "        salary.append(elem.find('nobr').getText().strip().encode('utf-8'))\n",
    "\n",
    "salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.indeed.com/rc/clk?jk=ca8146b5d7b02d5f&fccid=1818d10a60db56b4',\n",
       " 'http://www.indeed.com/rc/clk?jk=7a9fe7de1beb85f9&fccid=9605a3534a186df0',\n",
       " 'http://www.indeed.com/rc/clk?jk=35211e3965486c66&fccid=b144006bbf2d95a5',\n",
       " 'http://www.indeed.com/rc/clk?jk=90d5230fdc16cb28&fccid=7414fd5891b0ddd2',\n",
       " 'http://www.indeed.com/rc/clk?jk=1c41fd61f33c7f7a&fccid=9f1632b30ffb46f4',\n",
       " 'http://www.indeed.com/rc/clk?jk=e404043290252ddc&fccid=bca6f10d73dbbf6c',\n",
       " 'http://www.indeed.com/rc/clk?jk=845365829ba37eda&fccid=2973259ddc967948',\n",
       " 'http://www.indeed.com/rc/clk?jk=29209de19e74c885&fccid=5e964c4afc56b180',\n",
       " 'http://www.indeed.com/rc/clk?jk=812254ce6d0994d7&fccid=4e42ec53f4b93e02',\n",
       " 'http://www.indeed.com/rc/clk?jk=ca649839049927c4&fccid=44e7c30753d07f3b']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblink = []\n",
    "home_url = 'http://www.indeed.com'\n",
    "\n",
    "for elem in targetElements:\n",
    "        joblink.append(\"%s%s\" % (home_url,elem.find('a').get('href')))\n",
    "\n",
    "joblink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe based on information collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_date</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>companyname</th>\n",
       "      <th>location</th>\n",
       "      <th>advertised_number_of_days_ago</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>company_rating_counts</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>joblink</th>\n",
       "      <th>job_query_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>Program and Service Advisor</td>\n",
       "      <td>Victorian Government</td>\n",
       "      <td>Geelong VIC</td>\n",
       "      <td>12 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>In particular, a highly motivated individual w...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=ca8146b5d7b02d...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>Reliability Engineer - Christmas Creek</td>\n",
       "      <td>Fortescue Metals Group</td>\n",
       "      <td>Pilbara WA</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>23 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Analysis and reporting of fleet performance. T...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=7a9fe7de1beb85...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>Data Analyst / Administrator</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>28 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>21 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Undertake data analysis, cleansing, validation...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=35211e3965486c...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>Test Data Analyst</td>\n",
       "      <td>UniSuper</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>11 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Extensive data extract, analysis and reporting...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=90d5230fdc16cb...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>Stock Coordinator - Support Centre QLD</td>\n",
       "      <td>Lorna Jane</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>19 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Analysis of sales data and through reports to ...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=1c41fd61f33c7f...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_date                                jobtitle             companyname  \\\n",
       "0 2016-06-14             Program and Service Advisor    Victorian Government   \n",
       "1 2016-06-14  Reliability Engineer - Christmas Creek  Fortescue Metals Group   \n",
       "2 2016-06-14            Data Analyst / Administrator              Brookfield   \n",
       "3 2016-06-14                       Test Data Analyst                UniSuper   \n",
       "4 2016-06-14  Stock Coordinator - Support Centre QLD              Lorna Jane   \n",
       "\n",
       "        location advertised_number_of_days_ago company_rating  \\\n",
       "0    Geelong VIC                   12 days ago           None   \n",
       "1     Pilbara WA                    3 days ago           None   \n",
       "2     Sydney NSW                   28 days ago           None   \n",
       "3  Melbourne VIC                   11 days ago           None   \n",
       "4     Queensland                    3 days ago           None   \n",
       "\n",
       "  company_rating_counts salary  \\\n",
       "0                  None   None   \n",
       "1            23 reviews   None   \n",
       "2            21 reviews   None   \n",
       "3                  None   None   \n",
       "4            19 reviews   None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  In particular, a highly motivated individual w...   \n",
       "1  Analysis and reporting of fleet performance. T...   \n",
       "2  Undertake data analysis, cleansing, validation...   \n",
       "3  Extensive data extract, analysis and reporting...   \n",
       "4  Analysis of sales data and through reports to ...   \n",
       "\n",
       "                                             joblink  \\\n",
       "0  http://www.indeed.com/rc/clk?jk=ca8146b5d7b02d...   \n",
       "1  http://www.indeed.com/rc/clk?jk=7a9fe7de1beb85...   \n",
       "2  http://www.indeed.com/rc/clk?jk=35211e3965486c...   \n",
       "3  http://www.indeed.com/rc/clk?jk=90d5230fdc16cb...   \n",
       "4  http://www.indeed.com/rc/clk?jk=1c41fd61f33c7f...   \n",
       "\n",
       "                                    job_query_string  \n",
       "0  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "1  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "2  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "3  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "4  %22data+scientist%22+%22customer+analytics%22+...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns=['query_date','jobtitle','companyname','location',\n",
    "             'advertised_number_of_days_ago','company_rating',\n",
    "             'company_rating_counts','salary','summary',\n",
    "             'joblink','job_query_string']\n",
    "\n",
    "df_joblist = pd.DataFrame({'query_date':pd.to_datetime('today'),\n",
    "                                'jobtitle':jobtitle,\n",
    "                                'companyname':companyname,\n",
    "                                'location':location,\n",
    "                                'advertised_number_of_days_ago':advertised_number_of_days_ago,\n",
    "                                'company_rating':company_rating,\n",
    "                                'company_rating_counts':company_rating_counts,\n",
    "                                'salary':salary,\n",
    "                                'summary':summary,\n",
    "                                'joblink':joblink,\n",
    "                                'job_query_string':job_query_string},\n",
    "                         columns = df_columns)\n",
    "\n",
    "df_joblist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do:\n",
    "\n",
    "1) Source <br\\>\n",
    "2) Contract or not<br\\>\n",
    "3) Get full text from the job link. If source of job is indeed itself, then i imagine it's easier to source that. otherwise, the harder thing to do is to search for the short description for each row, find in parent website and then get it.<br\\>\n",
    "4) Start analysis of short text and job names already. Cluster jobs together.<br\\>\n",
    "5) Check how Jesse's and Sung's tuts got full text info about the jobs in order to map out the skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7_web_scraping",
   "language": "python",
   "name": "web_scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping indeed website for data science jobs based on Greg Reda's [excellent tutorial](http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/) and Jesse Steinweg's [excellent analysis](https://jessesw.com/Data-Science-Skills/) and finally, Sung Pil Moon's [awesome analysis](http://blog.nycdatascience.com/students-work/project-3-web-scraping-company-data-from-indeed-com-and-dice-com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Admin and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've already created a virtual environment in conda by downloading bs4. Please feel free to use my environment.yaml to create a similar virtual env. I'll update it as I go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) What do I want to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://au.indeed.com/jobs?as_and=&as_phr=&as_any=%22customer+analytics%22+%22data+analysis%22&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=50&l=&fromage=any&limit=10&sort=&psf=advsrch\n",
    "\n",
    "OR\n",
    "\n",
    "http://au.indeed.com/jobs?as_and=&as_phr=&as_any=%22customer+analytics%22+%22data+analysis%22&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=0&l=Sydney+NSW&fromage=last&limit=10&sort=&psf=advsrch\n",
    "\n",
    "in a nice tabular format for data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) String together webpage url based on different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create logic for converting different search parameters such as search query, city, salary etc. as separate lists and then stringing them together into one final query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_query = base_url + job_query_string + company_name + salary + location + fromage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start of the url - this will not change because I'm including search query to search\n",
    "# anywhere in the job ad. Not just the job title.\n",
    "base_url = 'http://au.indeed.com/jobs?as_and=&as_phr=&as_any='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job query string inputs as parameters are stored in job_query1, 2 and 3. Restrict to only 3 parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1 - collect 3 search queries<br/>\n",
    "When you refactor this, make sure this is converted into parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_query1 = 'data scientist'\n",
    "job_query2 = 'customer analytics'\n",
    "job_query3 = 'data analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2 - create query string in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%22data+scientist%22+%22customer+analytics%22+%22data+analysis%22'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) within search string, spaces are replaced by '+' in html\n",
    "# 2) each search query is preceded and succeeded by a \"%22\"\n",
    "# 3) string the elements of the list into one string separated by a \"+\"\n",
    "job_query_string = []\n",
    "job_query_string.append(\"%22\" + job_query1.replace(\" \",\"+\") + \"%22\")\n",
    "job_query_string.append(\"%22\" + job_query2.replace(\" \",\"+\") + \"%22\")\n",
    "job_query_string.append(\"%22\" + job_query3.replace(\" \",\"+\") + \"%22\")\n",
    "job_query_string = \"+\".join(job_query_string)\n",
    "job_query_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company name, salary, location, fromage - not working on these right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company_name=''\n",
    "salary=''\n",
    "location=''\n",
    "fromage='any'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://au.indeed.com/jobs?as_and=&as_phr=&as_any=%22data+scientist%22+%22customer+analytics%22+%22data+analysis%22&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=&radius=50&l=&fromage=any&limit=10&sort=&psf=advsrch'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_query = [base_url,job_query_string,'&as_not=&as_ttl=&as_cmp=',company_name,\n",
    "               '&jt=all&st=&salary=',salary,'&radius=50&l=',location,\n",
    "               '&fromage=',fromage,'&limit=10&sort=&psf=advsrch']\n",
    "final_query = \"\".join(final_query)\n",
    "final_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Open website and read it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: Open the first page <br/>\n",
    "Step2: Get the html of the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = urlopen(final_query).read()  \n",
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3: find out how many jobs returned from the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jobs 1 to 10 of 966'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_jobs_page_area = soup.find(id=\"searchCount\").string.encode('utf-8')\n",
    "number_of_jobs_page_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '10', '966']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_jobs = re.findall('\\d+', number_of_jobs_page_area)\n",
    "number_of_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_jobs = int(number_of_jobs[2])\n",
    "total_number_of_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4: calculate how many pages to scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#round up the # of records divided by 10 as the number of pages in order to ensure coverage. \n",
    "number_of_pages_to_scroll = np.ceil(total_number_of_jobs/10.0)\n",
    "number_of_pages_to_scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Load all the deets into separate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all the deets of each row. One row pertains to one job\n",
    "# incidentally, i noticed that the class \"row result\" was only picking 9 results in the first page.\n",
    "# this was because the last row was populated in another class 'lastRow row result'\n",
    "\n",
    "targetElements = soup.findAll('div', attrs = {'class' : ' row result'})\n",
    "targetElements.extend(soup.findAll('div', attrs = {'class' : 'lastRow row result'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(targetElements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*****************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for elem in targetElements:\n",
    "    #print elem # commenting out this line so as to remove metadata from the notebook\n",
    "    print \"\\n\"\n",
    "    print \"*****************************************************\"\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst - 4 Days A Week -',\n",
       " 'Reporting Data Analyst',\n",
       " u'Test Analyst \\u2013 Business Intelligence & Reporting',\n",
       " 'Data Analyst Road',\n",
       " 'Business Intelligence Analyst',\n",
       " 'Policy Officer / Data Analyst',\n",
       " 'Administration Support Officer - Melbourne - Victoria',\n",
       " 'Data Analyst - Health Data',\n",
       " 'Business Analyst - Market Data',\n",
       " 'Insight Analytics Manager']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobtitle = []\n",
    "for elem in targetElements:\n",
    "    #print elem.find('a', attrs = {'class':'turnstileLink'}).attrs['title']\n",
    "    jobtitle.append(elem.find('a', attrs = {'class':'turnstileLink'}).attrs['title'])\n",
    "\n",
    "jobtitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Company Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " 'NSW Government',\n",
       " 'Ashdown Consulting',\n",
       " 'Macquarie Group Limited',\n",
       " 'Australian Institute of Family Studies',\n",
       " 'Cancer Council Victoria',\n",
       " 'Daimler AG',\n",
       " 'Unisys']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyname = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('span', attrs = {'itemprop':'name'}) is None:\n",
    "        companyname.append(None)\n",
    "    else:\n",
    "        companyname.append(elem.find('span', attrs = {'itemprop':'name'})\n",
    "                                     .getText().strip().encode('utf-8'))    \n",
    "companyname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Melbourne VIC',\n",
       " 'Sydney NSW',\n",
       " 'Brisbane QLD',\n",
       " 'Sydney NSW',\n",
       " 'Sydney NSW',\n",
       " 'Sydney NSW',\n",
       " 'Melbourne VIC',\n",
       " 'North Sydney NSW',\n",
       " 'Sydney NSW',\n",
       " 'Melbourne VIC']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = []\n",
    "for elem in targetElements:\n",
    "    location.append(elem.find('span', attrs = {'itemprop':'addressLocality'}).getText().strip().encode('utf-8'))\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Performing complex data analysis to uncover trends. Critically evaluate data. Collect data through multiple channels;...',\n",
       " 'If you are successful you will be responsible for dashboarding and reporting with SSRS and data analysis. Due to new projects in the organisation a role is...',\n",
       " 'Good understanding of Data Warehouse & reporting concepts, with strong Data Analysis skills. Hands on testing experience with business intelligence / data...',\n",
       " 'We are looking for a Data Analyst who has knowledge and experience to undertake project management change requirements and operational data analysis....',\n",
       " 'Data visualisation and analysis of large data sets. Obtained an understanding of data analysis through experience gained in a reporting, analytics or insights...',\n",
       " 'The ideal candidate will have proven skills in data collection and analysis, as well as working with statistics....',\n",
       " 'Assist with month end ad-hoc reports and data analysis. It is essential that you have a professional customer service approach, experience handling telephone...',\n",
       " 'Clinical Data Analysis, Reporting and Monitoring. Some potential tender analysis. Assessing and reporting on data quality....',\n",
       " 'Provide advice and analysis on data and market data products for business units. Proficient in data analysis using the Microsoft Office suite....',\n",
       " 'Insight Analytics Manager. PwC is a world leader in the use of data analytics to help business and government clients make better decisions and improve their...']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = []\n",
    "for elem in targetElements:\n",
    "    summary.append(elem.find('span', attrs = {'class':'summary'}).getText().strip().encode('utf-8'))\n",
    "    \n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cant seem to get this to work for some reason\n",
    "company_rating = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('span', attrs = [{'class':'ratingNumber'}]) is None:\n",
    "        company_rating.append(None)\n",
    "    else:\n",
    "        company_rating.append(elem.find('span', attrs = {'class':'ratingNumber'})\n",
    "                                     .getText().strip().encode('utf-8'))\n",
    "    \n",
    "company_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company rating - Number of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['99 reviews',\n",
       " None,\n",
       " '9 reviews',\n",
       " '5 reviews',\n",
       " '17 reviews',\n",
       " None,\n",
       " '1,276 reviews',\n",
       " None,\n",
       " '17 reviews',\n",
       " '2,351 reviews']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_rating_counts = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('span', attrs = {'class':'slNoUnderline'}) is None:\n",
    "        company_rating_counts.append(None)\n",
    "    else:\n",
    "        company_rating_counts.append(elem.find('span', attrs = {'class':'slNoUnderline'})\n",
    "                                     .getText().strip().encode('utf-8'))\n",
    "\n",
    "company_rating_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advertised number of days ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11 days ago',\n",
       " '23 hours ago',\n",
       " '20 hours ago',\n",
       " '7 days ago',\n",
       " '16 days ago',\n",
       " '1 day ago',\n",
       " '26 minutes ago',\n",
       " '10 days ago',\n",
       " '13 days ago',\n",
       " '30+ days ago']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advertised_number_of_days_ago = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('span', attrs = {'class':'date'}) is None:\n",
    "        advertised_number_of_days_ago.append(None)\n",
    "    else:\n",
    "        advertised_number_of_days_ago.append(elem.find('span', attrs = {'class':'date'})\n",
    "                                     .getText().strip().encode('utf-8'))\n",
    "\n",
    "advertised_number_of_days_ago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " '$60,000 - $70,000 a year',\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = []\n",
    "for elem in targetElements:\n",
    "    if elem.find('nobr') is None:\n",
    "        salary.append(None)\n",
    "    else:\n",
    "        salary.append(elem.find('nobr').getText().strip().encode('utf-8'))\n",
    "\n",
    "salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.indeed.com/rc/clk?jk=0b4d12879ab9039a&fccid=77087bd1709a8148',\n",
       " 'http://www.indeed.com/rc/clk?jk=a1cddefcdf84358a&fccid=ce783271e420d14a',\n",
       " 'http://www.indeed.com/rc/clk?jk=43e8543e972f1260&fccid=14616a0554eb52c0',\n",
       " 'http://www.indeed.com/rc/clk?jk=8e6637871e0d5914&fccid=e60642a4b38e634f',\n",
       " 'http://www.indeed.com/rc/clk?jk=d0b72c272713c8a4&fccid=ca2285c3548c3efe',\n",
       " 'http://www.indeed.com/rc/clk?jk=728fe7507d385b30&fccid=ce783271e420d14a',\n",
       " 'http://www.indeed.com/rc/clk?jk=141c9045356a8de3&fccid=8177021cdb259d9d',\n",
       " 'http://www.indeed.com/rc/clk?jk=4fc279281b3db1aa&fccid=ce783271e420d14a',\n",
       " 'http://www.indeed.com/rc/clk?jk=19358d5471cc40cc&fccid=ca2285c3548c3efe',\n",
       " 'http://www.indeed.com/rc/clk?jk=29209de19e74c885&fccid=5e964c4afc56b180']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblink = []\n",
    "home_url = 'http://www.indeed.com'\n",
    "\n",
    "for elem in targetElements:\n",
    "        joblink.append(\"%s%s\" % (home_url,elem.find('a').get('href')))\n",
    "\n",
    "joblink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe based on information collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_date</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>companyname</th>\n",
       "      <th>location</th>\n",
       "      <th>advertised_number_of_days_ago</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>company_rating_counts</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>joblink</th>\n",
       "      <th>job_query_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>Data Analyst - 4 Days A Week -</td>\n",
       "      <td>None</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>11 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>99 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Performing complex data analysis to uncover tr...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=0b4d12879ab903...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>Reporting Data Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>If you are successful you will be responsible ...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=a1cddefcdf8435...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>Test Analyst – Business Intelligence &amp; Reporting</td>\n",
       "      <td>None</td>\n",
       "      <td>Brisbane QLD</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>None</td>\n",
       "      <td>9 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Good understanding of Data Warehouse &amp; reporti...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=43e8543e972f12...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>Data Analyst Road</td>\n",
       "      <td>NSW Government</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>7 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>5 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>We are looking for a Data Analyst who has know...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=8e6637871e0d59...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>Ashdown Consulting</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>16 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>17 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Data visualisation and analysis of large data ...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=d0b72c272713c8...</td>\n",
       "      <td>%22data+scientist%22+%22customer+analytics%22+...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_date                                          jobtitle  \\\n",
       "0 2016-06-17                    Data Analyst - 4 Days A Week -   \n",
       "1 2016-06-17                            Reporting Data Analyst   \n",
       "2 2016-06-17  Test Analyst – Business Intelligence & Reporting   \n",
       "3 2016-06-17                                 Data Analyst Road   \n",
       "4 2016-06-17                     Business Intelligence Analyst   \n",
       "\n",
       "          companyname       location advertised_number_of_days_ago  \\\n",
       "0                None  Melbourne VIC                   11 days ago   \n",
       "1                None     Sydney NSW                  23 hours ago   \n",
       "2                None   Brisbane QLD                  20 hours ago   \n",
       "3      NSW Government     Sydney NSW                    7 days ago   \n",
       "4  Ashdown Consulting     Sydney NSW                   16 days ago   \n",
       "\n",
       "  company_rating company_rating_counts salary  \\\n",
       "0           None            99 reviews   None   \n",
       "1           None                  None   None   \n",
       "2           None             9 reviews   None   \n",
       "3           None             5 reviews   None   \n",
       "4           None            17 reviews   None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Performing complex data analysis to uncover tr...   \n",
       "1  If you are successful you will be responsible ...   \n",
       "2  Good understanding of Data Warehouse & reporti...   \n",
       "3  We are looking for a Data Analyst who has know...   \n",
       "4  Data visualisation and analysis of large data ...   \n",
       "\n",
       "                                             joblink  \\\n",
       "0  http://www.indeed.com/rc/clk?jk=0b4d12879ab903...   \n",
       "1  http://www.indeed.com/rc/clk?jk=a1cddefcdf8435...   \n",
       "2  http://www.indeed.com/rc/clk?jk=43e8543e972f12...   \n",
       "3  http://www.indeed.com/rc/clk?jk=8e6637871e0d59...   \n",
       "4  http://www.indeed.com/rc/clk?jk=d0b72c272713c8...   \n",
       "\n",
       "                                    job_query_string  \n",
       "0  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "1  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "2  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "3  %22data+scientist%22+%22customer+analytics%22+...  \n",
       "4  %22data+scientist%22+%22customer+analytics%22+...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns=['query_date','jobtitle','companyname','location',\n",
    "             'advertised_number_of_days_ago','company_rating',\n",
    "             'company_rating_counts','salary','summary',\n",
    "             'joblink','job_query_string']\n",
    "\n",
    "df_joblist = pd.DataFrame({'query_date':pd.to_datetime('today'),\n",
    "                                'jobtitle':jobtitle,\n",
    "                                'companyname':companyname,\n",
    "                                'location':location,\n",
    "                                'advertised_number_of_days_ago':advertised_number_of_days_ago,\n",
    "                                'company_rating':company_rating,\n",
    "                                'company_rating_counts':company_rating_counts,\n",
    "                                'salary':salary,\n",
    "                                'summary':summary,\n",
    "                                'joblink':joblink,\n",
    "                                'job_query_string':job_query_string},\n",
    "                         columns = df_columns)\n",
    "\n",
    "df_joblist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the information collected above to create a function for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_job_board_data(job_query1,job_query2,job_query3):\n",
    "    #STEP1\n",
    "    # create query string in the required format\n",
    "    # 1) within search string, spaces are replaced by '+' in html\n",
    "    # 2) each search query is preceded and succeeded by a \"%22\"\n",
    "    # 3) string the elements of the list into one string separated by a \"+\"\n",
    "    job_query_string = []\n",
    "    job_query_string.append(\"%22\" + job_query1.replace(\" \",\"+\") + \"%22\")\n",
    "    job_query_string.append(\"%22\" + job_query2.replace(\" \",\"+\") + \"%22\")\n",
    "    job_query_string.append(\"%22\" + job_query3.replace(\" \",\"+\") + \"%22\")\n",
    "    job_query_string = \"+\".join(job_query_string)\n",
    "    \n",
    "    #STEP2\n",
    "    # start of the url - this will not change because I'm including search query to search\n",
    "    # anywhere in the job ad. Not just the job title.\n",
    "    base_url = 'http://au.indeed.com/jobs?as_and=&as_phr=&as_any='\n",
    "    \n",
    "    #STEP3\n",
    "    #company name, salary, location and fromage are not being worked on currently\n",
    "    company_name=''\n",
    "    salary=''\n",
    "    location=''\n",
    "    fromage='any'\n",
    "    \n",
    "    #STEP4\n",
    "    #create final query\n",
    "    final_query = [base_url,job_query_string,'&as_not=&as_ttl=&as_cmp=',company_name,\n",
    "               '&jt=all&st=&salary=',salary,'&radius=50&l=',location,\n",
    "               '&fromage=',fromage,'&limit=10&sort=&psf=advsrch']\n",
    "    final_query = \"\".join(final_query)\n",
    "    \n",
    "    #STEP5\n",
    "    #open website and read it\n",
    "    html = urlopen(final_query).read()  \n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    #STEP6\n",
    "    #determine total number of jobs and consequently, number of pages to scroll\n",
    "    number_of_jobs_page_area = soup.find(id=\"searchCount\").string.encode('utf-8')\n",
    "    number_of_jobs = re.findall('\\d+', number_of_jobs_page_area)\n",
    "    total_number_of_jobs = int(number_of_jobs[2])\n",
    "    number_of_pages_to_scroll = np.ceil(total_number_of_jobs/10.0)\n",
    "    \n",
    "    return number_of_pages_to_scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_job_board_data('data scientist','customer analytics','data analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create step to load details into list and subsequently, append this list into a dataframe. Then, create a logic for looping through the required number of pages and thereby create a solid dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7_web_scraping",
   "language": "python",
   "name": "web_scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
